"""GlossaryStore â€” æœ¯è¯­è¡¨æŒä¹…åŒ–å­˜å‚¨

æŒ‰é¢†åŸŸåˆ†ç±»ç»„ç»‡æœ¯è¯­è¡¨ï¼Œå­˜å‚¨ä¸º JSON æ–‡ä»¶ï¼ˆTranslation/glossaries/{domain}.jsonï¼‰ã€‚
æ”¯æŒåŠ è½½ã€ä¿å­˜ã€å¤‡ä»½ã€åˆå¹¶ã€æŸ¥è¯¢å’Œæ›´æ–°æ“ä½œã€‚

å­˜å‚¨æ ¼å¼:
{
  "domain": "nlp",
  "entries": [
    {"english": "Transformer", "chinese": "Transformer", "keep_english": true, ...},
    ...
  ],
  "updated_at": "2024-01-01T00:00:00"
}

Requirements: 3.4, 7.3, 7.5
"""

from __future__ import annotations

import asyncio
import json
import logging
import shutil
from datetime import datetime
from pathlib import Path

import aiofiles

from agent.models import GlossaryEntry

logger = logging.getLogger(__name__)

# glossary_store.py ä½äº test/agent/tools/
# parents: [0]=tools [1]=agent [2]=test
PROJECT_ROOT = Path(__file__).resolve().parents[2]
GLOSSARY_DIR = PROJECT_ROOT / "Translation" / "glossaries"


class GlossaryStore:
    """æœ¯è¯­è¡¨æŒä¹…åŒ–å­˜å‚¨

    ç®¡ç† Translation/glossaries/ ç›®å½•ä¸‹æŒ‰é¢†åŸŸå‘½åçš„ JSON æœ¯è¯­è¡¨æ–‡ä»¶ã€‚
    æä¾› CRUD æ“ä½œå’Œå¤‡ä»½æœºåˆ¶ã€‚

    Attributes:
        glossary_dir: æœ¯è¯­è¡¨å­˜å‚¨ç›®å½•ï¼Œé»˜è®¤ä¸º Translation/glossaries/
    """

    _lock = asyncio.Lock()

    def __init__(self, glossary_dir: Path | None = None) -> None:
        """åˆå§‹åŒ– GlossaryStore

        Args:
            glossary_dir: è‡ªå®šä¹‰æœ¯è¯­è¡¨å­˜å‚¨ç›®å½•ï¼ˆä¸»è¦ç”¨äºæµ‹è¯•ï¼‰ã€‚
                         é»˜è®¤ä½¿ç”¨ Translation/glossaries/ã€‚
        """
        self.glossary_dir = glossary_dir or GLOSSARY_DIR

    def _domain_path(self, domain: str) -> Path:
        """è·å–æŒ‡å®šé¢†åŸŸçš„æœ¯è¯­è¡¨æ–‡ä»¶è·¯å¾„"""
        return self.glossary_dir / f"{domain}.json"

    async def load(self, domain: str) -> list[GlossaryEntry]:
        """åŠ è½½æŒ‡å®šé¢†åŸŸçš„æœ¯è¯­è¡¨

        Args:
            domain: é¢†åŸŸåç§°ï¼ˆå¦‚ "nlp"ã€"cv"ï¼‰

        Returns:
            æœ¯è¯­æ¡ç›®åˆ—è¡¨ã€‚å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–è§£æå¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨ã€‚
        """
        path = self._domain_path(domain)
        if not path.exists():
            logger.debug(f"æœ¯è¯­è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {path}")
            return []

        try:
            async with aiofiles.open(path, "r", encoding="utf-8") as f:
                content = await f.read()
            data = json.loads(content)
            entries = [
                GlossaryEntry.from_dict(item)
                for item in data.get("entries", [])
            ]
            logger.info(f"ğŸ“– å·²åŠ è½½æœ¯è¯­è¡¨ [{domain}]: {len(entries)} æ¡")
            return entries
        except (json.JSONDecodeError, IOError, KeyError) as exc:
            logger.warning(f"åŠ è½½æœ¯è¯­è¡¨å¤±è´¥ [{domain}]: {exc}")
            return []

    async def save(self, domain: str, entries: list[GlossaryEntry]) -> None:
        """ä¿å­˜æœ¯è¯­è¡¨åˆ°æ–‡ä»¶

        å°†æœ¯è¯­æ¡ç›®åˆ—è¡¨åºåˆ—åŒ–ä¸º JSON å¹¶å†™å…¥
        Translation/glossaries/{domain}.jsonã€‚

        Args:
            domain: é¢†åŸŸåç§°
            entries: æœ¯è¯­æ¡ç›®åˆ—è¡¨
        """
        async with self._lock:
            self.glossary_dir.mkdir(parents=True, exist_ok=True)
            path = self._domain_path(domain)

            data = {
                "domain": domain,
                "entries": [entry.to_dict() for entry in entries],
                "updated_at": datetime.now().isoformat(timespec="seconds"),
            }

            async with aiofiles.open(path, "w", encoding="utf-8") as f:
                await f.write(json.dumps(data, ensure_ascii=False, indent=2))

            logger.info(f"ğŸ’¾ å·²ä¿å­˜æœ¯è¯­è¡¨ [{domain}]: {len(entries)} æ¡")

    async def backup(self, domain: str) -> Path | None:
        """åˆ›å»ºæœ¯è¯­è¡¨å¤‡ä»½

        å°†å½“å‰æœ¯è¯­è¡¨æ–‡ä»¶å¤åˆ¶ä¸º {domain}.{timestamp}.bak.jsonã€‚
        å¦‚æœåŸæ–‡ä»¶ä¸å­˜åœ¨åˆ™è·³è¿‡ã€‚

        Args:
            domain: é¢†åŸŸåç§°

        Returns:
            å¤‡ä»½æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœåŸæ–‡ä»¶ä¸å­˜åœ¨åˆ™è¿”å› Noneã€‚
        """
        path = self._domain_path(domain)
        if not path.exists():
            logger.debug(f"æ— éœ€å¤‡ä»½ï¼Œæœ¯è¯­è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {path}")
            return None

        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        backup_name = f"{domain}.{timestamp}.bak.json"
        backup_path = self.glossary_dir / backup_name

        shutil.copy2(str(path), str(backup_path))
        logger.info(f"ğŸ“‹ å·²åˆ›å»ºæœ¯è¯­è¡¨å¤‡ä»½: {backup_name}")
        return backup_path

    async def merge(
        self, domain: str, new_entries: list[GlossaryEntry]
    ) -> list[dict]:
        """åˆå¹¶æ–°æœ¯è¯­åˆ°å·²æœ‰æœ¯è¯­è¡¨

        åˆå¹¶è§„åˆ™ï¼š
        - å·²æœ‰æœ¯è¯­çš„ç¿»è¯‘ä¿æŒä¸å˜ï¼ˆä¼˜å…ˆä½¿ç”¨å·²æœ‰ç¿»è¯‘ï¼‰
        - æ–°æœ¯è¯­è¢«æ·»åŠ åˆ°æœ¯è¯­è¡¨ä¸­
        - åŒä¸€è‹±æ–‡æœ¯è¯­æœ‰ä¸åŒä¸­æ–‡ç¿»è¯‘æ—¶ï¼Œè®°å½•ä¸ºå†²çª

        Args:
            domain: é¢†åŸŸåç§°
            new_entries: æ–°æå–çš„æœ¯è¯­æ¡ç›®åˆ—è¡¨

        Returns:
            å†²çªåˆ—è¡¨ï¼Œæ¯ä¸ªå†²çªä¸º dict:
            {"english": str, "existing": str, "incoming": str}
        """
        existing = await self.load(domain)

        # æ„å»ºå·²æœ‰æœ¯è¯­çš„ç´¢å¼•ï¼ˆè‹±æ–‡å°å†™ -> GlossaryEntryï¼‰
        existing_map: dict[str, GlossaryEntry] = {
            entry.english.lower(): entry for entry in existing
        }

        conflicts: list[dict] = []

        for new_entry in new_entries:
            key = new_entry.english.lower()
            if key in existing_map:
                old = existing_map[key]
                # æ£€æµ‹å†²çªï¼šåŒä¸€è‹±æ–‡æœ¯è¯­çš„ä¸åŒä¸­æ–‡ç¿»è¯‘
                if old.chinese != new_entry.chinese:
                    conflicts.append(
                        {
                            "english": new_entry.english,
                            "existing": old.chinese,
                            "incoming": new_entry.chinese,
                        }
                    )
                # å·²æœ‰æœ¯è¯­ä¿æŒä¸å˜ï¼ˆä¸è¦†ç›–ï¼‰
            else:
                # æ–°æœ¯è¯­ï¼šæ·»åŠ åˆ°æœ¯è¯­è¡¨
                new_entry.domain = domain
                new_entry.updated_at = datetime.now().isoformat(timespec="seconds")
                existing_map[key] = new_entry

        # å¤‡ä»½å¹¶ä¿å­˜åˆå¹¶åçš„æœ¯è¯­è¡¨
        await self.backup(domain)
        merged = list(existing_map.values())
        await self.save(domain, merged)

        if conflicts:
            logger.warning(
                f"âš ï¸ æœ¯è¯­åˆå¹¶å†²çª [{domain}]: {len(conflicts)} ä¸ª"
            )
        logger.info(
            f"ğŸ”€ æœ¯è¯­åˆå¹¶å®Œæˆ [{domain}]: åˆå¹¶å {len(merged)} æ¡"
        )
        return conflicts

    async def query(
        self, term: str, domain: str = ""
    ) -> list[GlossaryEntry]:
        """æŸ¥è¯¢æœ¯è¯­ï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰

        åœ¨æŒ‡å®šé¢†åŸŸï¼ˆæˆ–æ‰€æœ‰é¢†åŸŸï¼‰ä¸­æœç´¢åŒ…å«æŸ¥è¯¢è¯çš„æœ¯è¯­ã€‚
        åŒ¹é…è§„åˆ™ï¼šè‹±æ–‡æˆ–ä¸­æ–‡å­—æ®µåŒ…å«æŸ¥è¯¢è¯ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰ã€‚

        Args:
            term: æŸ¥è¯¢è¯
            domain: é™å®šæœç´¢çš„é¢†åŸŸã€‚ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºæœç´¢æ‰€æœ‰é¢†åŸŸã€‚

        Returns:
            åŒ¹é…çš„æœ¯è¯­æ¡ç›®åˆ—è¡¨
        """
        term_lower = term.lower()
        results: list[GlossaryEntry] = []

        if domain:
            domains = [domain]
        else:
            # æœç´¢æ‰€æœ‰é¢†åŸŸ
            domains = self._list_domains()

        for d in domains:
            entries = await self.load(d)
            for entry in entries:
                if (
                    term_lower in entry.english.lower()
                    or term_lower in entry.chinese.lower()
                ):
                    results.append(entry)

        logger.debug(
            f"ğŸ” æœ¯è¯­æŸ¥è¯¢ '{term}' (domain={domain or 'all'}): "
            f"æ‰¾åˆ° {len(results)} æ¡"
        )
        return results

    async def update_entry(
        self,
        domain: str,
        english: str,
        chinese: str,
        source: str = "user_edit",
    ) -> None:
        """æ›´æ–°æˆ–æ–°å¢å•ä¸ªæœ¯è¯­æ¡ç›®

        å¦‚æœæœ¯è¯­å·²å­˜åœ¨åˆ™æ›´æ–°å…¶ä¸­æ–‡ç¿»è¯‘å’Œæ¥æºï¼›
        å¦‚æœä¸å­˜åœ¨åˆ™æ–°å¢æ¡ç›®ã€‚æ›´æ–°å‰ä¼šåˆ›å»ºå¤‡ä»½ã€‚

        Args:
            domain: é¢†åŸŸåç§°
            english: è‹±æ–‡æœ¯è¯­
            chinese: ä¸­æ–‡ç¿»è¯‘
            source: æ¥æºæ ‡è¯†ï¼ˆé»˜è®¤ "user_edit"ï¼‰
        """
        entries = await self.load(domain)

        # æŸ¥æ‰¾å·²æœ‰æ¡ç›®
        found = False
        for entry in entries:
            if entry.english.lower() == english.lower():
                entry.chinese = chinese
                entry.source = source
                entry.updated_at = datetime.now().isoformat(timespec="seconds")
                found = True
                break

        if not found:
            entries.append(
                GlossaryEntry(
                    english=english,
                    chinese=chinese,
                    domain=domain,
                    source=source,
                    updated_at=datetime.now().isoformat(timespec="seconds"),
                )
            )

        # å¤‡ä»½å¹¶ä¿å­˜
        await self.backup(domain)
        await self.save(domain, entries)

        action = "æ›´æ–°" if found else "æ–°å¢"
        logger.info(f"âœï¸ æœ¯è¯­{action} [{domain}]: {english} â†’ {chinese}")

    def _list_domains(self) -> list[str]:
        """åˆ—å‡ºæ‰€æœ‰å·²æœ‰çš„é¢†åŸŸåç§°

        Returns:
            é¢†åŸŸåç§°åˆ—è¡¨ï¼ˆä»æ–‡ä»¶åæ¨æ–­ï¼‰
        """
        if not self.glossary_dir.exists():
            return []
        return [
            p.stem
            for p in self.glossary_dir.glob("*.json")
            if not p.stem.endswith(".bak")
            and ".bak." not in p.name
        ]

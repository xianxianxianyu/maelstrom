"""LLM ç®¡çº¿ â€” PyMuPDF è§£æ â†’ æ‘˜è¦åˆ†æ â†’ é€å—ç¿»è¯‘ â†’ ç»„è£… Markdown"""
import asyncio
import logging
import time
from pathlib import Path
from typing import Optional

import aiofiles

from app.services.pdf_parser import PDFParser
from app.services.translator import TranslationService
from app.services.markdown_builder import MarkdownBuilder
from app.services.post_processor import PostProcessor
from app.services.text_processing import merge_text_blocks
from app.services.text_processing import postprocess_translated_markdown
from app.services.prompt_generator import (
    generate_prompt_profile, extract_abstract_from_blocks,
)
from core.llm.config import FunctionKey
from .base import BasePipeline, PipelineResult, CancellationToken

logger = logging.getLogger(__name__)


class LLMPipeline(BasePipeline):
    """çº¯ LLM ç®¡çº¿ï¼šPyMuPDF è§£æ â†’ åˆ†ææ‘˜è¦ç”Ÿæˆ prompt â†’ é€å—ç¿»è¯‘ â†’ ç»„è£… markdown"""

    async def execute(self, file_content: bytes, filename: str) -> PipelineResult:
        t0 = time.time()
        logger.info("ğŸ”¤ LLM ç®¡çº¿å¯åŠ¨ï¼ˆPyMuPDF è§£æï¼‰...")

        # å†™å…¥ä¸´æ—¶æ–‡ä»¶ä¾› PyMuPDF è¯»å–
        temp_path = Path(f"temp/{filename}")
        temp_path.parent.mkdir(exist_ok=True)
        async with aiofiles.open(temp_path, "wb") as f:
            await f.write(file_content)

        try:
            parser = PDFParser()
            translator = await TranslationService.from_manager(FunctionKey.TRANSLATION)
            builder = MarkdownBuilder()

            parsed = await parser.process(temp_path)
            total_pages = len(parsed.pages)
            logger.info(f"   PDF è§£æå®Œæˆ: {total_pages} é¡µ")

            # Step 0: æå–æ‘˜è¦ â†’ ç”Ÿæˆå®šåˆ¶åŒ–ç¿»è¯‘ prompt
            abstract_text = extract_abstract_from_blocks(parsed.pages)
            profile = await generate_prompt_profile(abstract_text, translator, self.system_prompt)
            final_prompt = profile.translation_prompt
            logger.info(f"ğŸ“‹ ç¿»è¯‘ Prompt å·²ç”Ÿæˆ | é¢†åŸŸ: {profile.domain} | æœ¯è¯­: {len(profile.terminology)} ä¸ª")

            # å¹¶å‘ç¿»è¯‘
            post_processor = PostProcessor()
            sem = asyncio.Semaphore(self.CONCURRENCY)

            async def translate_block(block):
                async with sem:
                    self.token.check()
                    block.text = await translator.translate(block.text, final_prompt)
                    block.text = post_processor.process(block.text)

            for idx, page in enumerate(parsed.pages):
                self.token.check()

                page_start = time.time()
                text_blocks = [b for b in page.blocks if b.type == "text" and b.text.strip()]
                merged_blocks = merge_text_blocks(text_blocks)

                if merged_blocks:
                    await asyncio.gather(*(translate_block(b) for b in merged_blocks))
                    non_text = [b for b in page.blocks if b.type != "text" or not b.text.strip()]
                    page.blocks = non_text + merged_blocks
                    page.blocks.sort(key=lambda b: b.y_pos)

                    elapsed = time.time() - page_start
                    pct = (idx + 1) / total_pages * 100
                    logger.info(
                        f"   ç¿»è¯‘è¿›åº¦: [{idx + 1}/{total_pages}] {pct:.0f}% "
                        f"| {len(text_blocks)}â†’{len(merged_blocks)} å— | {elapsed:.1f}s"
                    )

            md, images = await builder.process(parsed)
            # åå¤„ç† â€” å¼•ç”¨ä¸Šæ ‡ã€å›¾æ³¨æ ¼å¼åŒ–
            md = postprocess_translated_markdown(md)
            logger.info(f"âœ… LLM ç®¡çº¿å®Œæˆ | {len(md)} å­—ç¬¦ | è€—æ—¶ {time.time() - t0:.1f}s")

            return PipelineResult(
                translated_md=md,
                images=images,
                prompt_profile=profile,
            )
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_path.exists():
                try:
                    temp_path.unlink()
                except Exception:
                    pass

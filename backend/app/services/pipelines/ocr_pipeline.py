"""OCR + ç¿»è¯‘ç®¡çº¿ â€” OCR è¯†åˆ« â†’ é¢„å¤„ç† â†’ åˆ†æ®µ â†’ ç¿»è¯‘æ–‡æœ¬æ®µ â†’ é‡ç»„ Markdown"""
from __future__ import annotations

import asyncio
import logging
import time
from typing import Optional

from backend.app.services.translator import TranslationService
from backend.app.services.ocr_service import OCRService
from backend.app.services.post_processor import PostProcessor
from backend.app.services.text_processing import (
    split_md_segments,
    preprocess_ocr_markdown,
    protect_inline_latex,
    restore_inline_latex,
    postprocess_translated_markdown,
)
from backend.app.services.prompt_generator import (
    PromptProfile, generate_prompt_profile, extract_abstract_from_markdown,
)
from core.llm.config import FunctionKey
from .base import BasePipeline, PipelineResult, CancellationToken

logger = logging.getLogger(__name__)


class OCRPipeline(BasePipeline):
    """OCR + ç¿»è¯‘ç®¡çº¿ï¼šOCR â†’ é¢„å¤„ç† â†’ åˆ†ææ‘˜è¦ â†’ åˆ†æ®µç¿»è¯‘ â†’ é‡ç»„"""

    async def execute(
        self,
        file_content: bytes,
        filename: str,
        existing_ocr_md: str | None = None,
        existing_ocr_images: dict[str, bytes] | None = None,
    ) -> PipelineResult:
        t0 = time.time()
        logger.info("ğŸ” OCR + ç¿»è¯‘ç®¡çº¿å¯åŠ¨...")

        # Step 1: OCR è¯†åˆ«ï¼ˆå¦‚æœå·²æœ‰ OCR ç»“æœåˆ™è·³è¿‡ï¼‰
        if existing_ocr_md:
            ocr_md = existing_ocr_md
            ocr_images = existing_ocr_images or {}
            logger.info(f"   å¤ç”¨å·²æœ‰ OCR ç»“æœ | {len(ocr_md)} å­—ç¬¦ï¼ˆè·³è¿‡ OCRï¼‰")
            await self._emit("ocr_done", 40, {
                "message": f"å¤ç”¨å·²æœ‰ OCR ç»“æœ: {len(ocr_md)} å­—ç¬¦",
            })
        else:
            await self._emit("ocr_start", 30, {"message": "OCR è¯†åˆ«ä¸­..."})
            ocr_service = await OCRService.from_manager()
            ocr_md, ocr_images = await ocr_service.recognize(file_content, file_type=0)
            elapsed_ocr = time.time() - t0
            logger.info(f"   OCR å®Œæˆ | {len(ocr_md)} å­—ç¬¦ | è€—æ—¶ {elapsed_ocr:.1f}s")
            await self._emit("ocr_done", 40, {
                "message": f"OCR å®Œæˆ: {len(ocr_md)} å­—ç¬¦, è€—æ—¶ {elapsed_ocr:.1f}s",
            })

        self.token.check()

        # Step 1.5: é¢„å¤„ç† â€” HTML table â†’ MD table, å›¾æ³¨æ ‡å‡†åŒ–
        processed_md = preprocess_ocr_markdown(ocr_md)
        logger.info(f"   é¢„å¤„ç†å®Œæˆ | {len(ocr_md)} â†’ {len(processed_md)} å­—ç¬¦")
        await self._emit("preprocess", 42, {
            "message": f"é¢„å¤„ç†å®Œæˆ: {len(ocr_md)} â†’ {len(processed_md)} å­—ç¬¦",
        })

        # Step 2: æå–æ‘˜è¦ â†’ ç”Ÿæˆå®šåˆ¶åŒ–ç¿»è¯‘ prompt
        translator = await TranslationService.from_manager(FunctionKey.TRANSLATION)
        if self.system_prompt:
            final_prompt = self.system_prompt
            profile = PromptProfile(translation_prompt=final_prompt)
            logger.info("ğŸ“‹ ä½¿ç”¨ä¸Šå±‚ä¼ å…¥çš„ç¿»è¯‘ Promptï¼ˆè·³è¿‡é‡å¤ç”Ÿæˆï¼‰")
            await self._emit("prompt_ready", 45, {
                "message": "ä½¿ç”¨ Agent ç”Ÿæˆçš„ç¿»è¯‘ Prompt",
            })
        else:
            await self._emit("prompt_generating", 43, {
                "message": "åˆ†æè®ºæ–‡é¢†åŸŸå’Œæœ¯è¯­...",
            })
            abstract_text = extract_abstract_from_markdown(processed_md)
            profile = await generate_prompt_profile(abstract_text, translator, self.system_prompt)
            final_prompt = profile.translation_prompt
            logger.info(f"ğŸ“‹ ç¿»è¯‘ Prompt å·²ç”Ÿæˆ | é¢†åŸŸ: {profile.domain} | æœ¯è¯­: {len(profile.terminology)} ä¸ª")
            await self._emit("prompt_ready", 45, {
                "message": f"Prompt å·²ç”Ÿæˆ | é¢†åŸŸ: {profile.domain} | æœ¯è¯­: {len(profile.terminology)} ä¸ª",
                "domain": profile.domain,
                "term_count": len(profile.terminology),
            })

        self.token.check()

        # Step 3: åˆ†æ®µ
        segments = split_md_segments(processed_md)
        text_segments = [s for s in segments if s["type"] == "text"]
        logger.info(f"   åˆ†æ®µå®Œæˆ | æ€» {len(segments)} æ®µ | æ–‡æœ¬ {len(text_segments)} æ®µå¾…ç¿»è¯‘")
        await self._emit("segmented", 47, {
            "message": f"åˆ†æ®µå®Œæˆ: {len(text_segments)} æ®µæ–‡æœ¬å¾…ç¿»è¯‘",
            "total_segments": len(segments),
            "text_segments": len(text_segments),
        })

        # Step 4: å¹¶å‘ç¿»è¯‘æ–‡æœ¬æ®µï¼ˆå¸¦ LaTeX ä¿æŠ¤ï¼‰
        post_processor = PostProcessor()
        sem = asyncio.Semaphore(self.CONCURRENCY)
        translated_count = 0
        total_text = len(text_segments)

        async def translate_segment(seg: dict):
            nonlocal translated_count
            async with sem:
                self.token.check()
                original = seg["content"]

                # ä¿æŠ¤è¡Œå†… LaTeX å…¬å¼
                protected, latex_map = protect_inline_latex(original)

                translated = await translator.translate(protected, final_prompt)
                translated = post_processor.process(translated)

                # è¿˜åŸ LaTeX å…¬å¼
                if latex_map:
                    translated = restore_inline_latex(translated, latex_map)

                seg["content"] = translated
                translated_count += 1
                pct = translated_count / max(total_text, 1)
                # ç¿»è¯‘è¿›åº¦æ˜ å°„åˆ° 50-90 åŒºé—´
                progress = 50 + int(pct * 40)
                if translated_count % 3 == 0 or translated_count == total_text:
                    logger.info(
                        f"   ç¿»è¯‘è¿›åº¦: [{translated_count}/{total_text}] "
                        f"{pct * 100:.0f}%"
                    )
                    await self._emit("translating", progress, {
                        "message": f"ç¿»è¯‘ä¸­: {translated_count}/{total_text} æ®µ ({pct * 100:.0f}%)",
                        "current": translated_count,
                        "total": total_text,
                    })

        await self._emit("translating", 50, {
            "message": f"å¼€å§‹ç¿»è¯‘ {total_text} æ®µæ–‡æœ¬...",
            "current": 0,
            "total": total_text,
        })
        await asyncio.gather(*(translate_segment(s) for s in text_segments))

        # Step 5: é‡ç»„
        parts = [seg["content"] for seg in segments]
        result_md = "\n\n".join(parts)

        # Step 6: åå¤„ç† â€” å¼•ç”¨ä¸Šæ ‡ã€å›¾æ³¨æ ¼å¼åŒ–
        result_md = postprocess_translated_markdown(result_md)
        total_time = time.time() - t0
        logger.info(f"âœ… OCR + ç¿»è¯‘ç®¡çº¿å®Œæˆ | {len(result_md)} å­—ç¬¦ | è€—æ—¶ {total_time:.1f}s")
        await self._emit("pipeline_done", 92, {
            "message": f"ç¿»è¯‘ç®¡çº¿å®Œæˆ: {len(result_md)} å­—ç¬¦, è€—æ—¶ {total_time:.1f}s",
        })

        return PipelineResult(
            translated_md=result_md,
            ocr_md=ocr_md,
            ocr_images=ocr_images,
            prompt_profile=profile,
        )
